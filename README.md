# ğŸ¤– Analytics Engineering with LLM

> **DemonstraÃ§Ã£o prÃ¡tica de Analytics Engineering usando Python, SQL e LLM para ExtraÃ§Ã£o de Insights em Pipelines de Engenharia de Dados**

Este projeto demonstra como implementar uma pipeline de **analytics engineering** que combina bancos de dados PostgreSQL, processamento de dados com Python e geraÃ§Ã£o de insights automatizados usando **Large Language Models (LLMs)**. Utilizamos o **Ollama** com o modelo **Llama3** para anÃ¡lise inteligente de padrÃµes de compras de clientes.

## ğŸ¯ Objetivo

Implementar uma soluÃ§Ã£o completa de analytics engineering usando:
- **PostgreSQL** como banco de dados relacional
- **Python** para ETL e orquestraÃ§Ã£o de pipelines
- **SQLAlchemy** e **psycopg2** para conexÃ£o com banco de dados
- **LangChain** + **Ollama (Llama3)** para geraÃ§Ã£o de insights com IA
- **Docker** para ambiente de desenvolvimento isolado e reproduzÃ­vel
- **Pre-commit** para qualidade de cÃ³digo (Black, Flake8, isort, Bandit)

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Files     â”‚â”€â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚â”€â”€â”€â”€â–¶â”‚  Python Query   â”‚â”€â”€â”€â”€â–¶â”‚   Ollama LLM    â”‚
â”‚  (Raw Data)     â”‚     â”‚   (Database)    â”‚     â”‚  (Analytics)    â”‚     â”‚   (Insights)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   data/raw/                 :5433              src/3_query.py         src/4_llm.py
                                                                              â”‚
                                                                              â–¼
                                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                    â”‚   CSV Output    â”‚
                                                                    â”‚   (Insights)    â”‚
                                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    data/outputs/
```

## ğŸ“ Estrutura do Projeto

```
analytics-engineering-with-llm/
â”œâ”€â”€ ğŸ“„ README.md                    # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ³ dockerfile                   # Imagem Docker PostgreSQL
â”œâ”€â”€ ğŸ³ docker-compose.yml           # OrquestraÃ§Ã£o do ambiente
â”œâ”€â”€ ğŸ“¦ pyproject.toml               # DependÃªncias e configuraÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ”§ .pre-commit-config.yaml      # ConfiguraÃ§Ã£o de hooks de qualidade
â”œâ”€â”€ ğŸ .python-version              # VersÃ£o do Python (3.12.9)
â”œâ”€â”€ ğŸ“ LICENSE                      # LicenÃ§a MIT
â”œâ”€â”€ ğŸ™ .gitignore                   # Arquivos e pastas ignorados pelo Git
â”œâ”€â”€ ğŸ”’ .env                         # VariÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ ğŸ—‚ï¸ src/
â”‚   â”œâ”€â”€ ğŸ main.py                  # Pipeline principal (orquestrador)
â”‚   â”œâ”€â”€ ğŸ 1_create_db.py           # CriaÃ§Ã£o do schema e tabelas
â”‚   â”œâ”€â”€ ğŸ 2_load_db.py             # Carga de dados CSV para PostgreSQL
â”‚   â”œâ”€â”€ ğŸ 3_query.py               # ExecuÃ§Ã£o de queries SQL
â”‚   â””â”€â”€ ğŸ 4_llm.py                 # GeraÃ§Ã£o de insights com LLM
â”œâ”€â”€ ğŸ—‚ï¸ sql/
â”‚   â”œâ”€â”€ ğŸ“‹ script.sql               # Script de criaÃ§Ã£o do schema e tabelas
â”‚   â””â”€â”€ ğŸ“‹ query.sql                # Query de anÃ¡lise de compras
â””â”€â”€ ğŸ—‚ï¸ data/
    â”œâ”€â”€ ğŸ“‚ raw/                     # Dados brutos (CSV)
    â”‚   â”œâ”€â”€ ğŸ“Š customers.csv        # Dados de clientes
    â”‚   â”œâ”€â”€ ğŸ“Š products.csv         # Dados de produtos
    â”‚   â””â”€â”€ ğŸ“Š purchases.csv        # Dados de compras
    â””â”€â”€ ğŸ“‚ outputs/                 # Dados processados
        â””â”€â”€ ğŸ“Š insights.csv         # Insights gerados pelo LLM
```

## ğŸ› ï¸ PrÃ©-requisitos

### ğŸ“‹ Ferramentas NecessÃ¡rias
- **Python 3.12+**
- **Docker** e **Docker Compose**
- **Poetry** (gerenciador de dependÃªncias)
- **Ollama** com modelo **Llama3** instalado
- **DBeaver** ou outro cliente SQL (opcional)

### ğŸ”‘ ConfiguraÃ§Ã£o de Credenciais

Criar um arquivo `.env` na raiz do projeto:

```bash
# PostgreSQL credentials
POSTGRES_USER=postgres
POSTGRES_PASSWORD=sua_senha_segura
POSTGRES_DB=postgres
```

## ğŸš€ Roadmap

### 1ï¸âƒ£ Clonar o RepositÃ³rio

```bash
git clone https://github.com/JadesonBruno/analytics-engineering-with-llm.git
cd analytics-engineering-with-llm
```

### 2ï¸âƒ£ Configurar o Ambiente Python

```bash
# Instalar dependÃªncias com Poetry
poetry install

# Ativar o ambiente virtual
source .venv/Scripts/activate  # Windows
```

### 3ï¸âƒ£ Configurar o Ambiente Docker

```bash
# Build e start do container PostgreSQL
docker-compose up -d --build
```

### 4ï¸âƒ£ Instalar o Ollama e o Modelo Llama3

```bash
# Instalar Ollama (Windows/Mac/Linux)
# Acesse: https://ollama.ai/download

# Baixar o modelo Llama3
ollama pull llama3

# Verificar se o modelo estÃ¡ disponÃ­vel
ollama list
```

### 5ï¸âƒ£ Executar o Pipeline Completo

```bash
# Executar todos os scripts em sequÃªncia
python src/main.py
```

Ou executar cada etapa individualmente:

```bash
# 1. Criar schema e tabelas no PostgreSQL
python src/1_create_db.py

# 2. Carregar dados CSV para o banco
python src/2_load_db.py

# 3. Executar query de anÃ¡lise
python src/3_query.py

# 4. Gerar insights com LLM
python src/4_llm.py
```

### 6ï¸âƒ£ Verificar os Resultados

Os insights gerados pelo LLM serÃ£o salvos em `data/outputs/insights.csv` e exibidos no terminal.

## âš™ï¸ ConfiguraÃ§Ãµes Principais

### ğŸ³ Dockerfile

```dockerfile
# Use the official PostgreSQL image as base
FROM postgres:18

# Image maintainer
LABEL maintainer="jadesonbruno.a@outlook.com"
```

### ğŸ˜ Docker Compose

```yaml
services:
  db_source:
    build:
      context: .
      dockerfile: dockerfile
    ports:
      - "5433:5432"
    env_file:
      - .env
```

### ğŸ”§ Schema do Banco de Dados

```sql
-- Schema: analytics_engineering
CREATE SCHEMA analytics_engineering;

-- Tabelas: customers, products, purchases
CREATE TABLE analytics_engineering.customers (
    customer_id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(101),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE analytics_engineering.products (
    product_id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    price DECIMAL(10, 2)
);

CREATE TABLE analytics_engineering.purchases (
    purchase_id SERIAL PRIMARY KEY,
    customer_id INTEGER REFERENCES analytics_engineering.customers(customer_id),
    product_id INTEGER REFERENCES analytics_engineering.products(product_id),
    purchase_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### ğŸ¤– ConfiguraÃ§Ã£o do LLM

O projeto utiliza **LangChain** com **Ollama** para executar o modelo **Llama3** localmente:

```python
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Instanciar o LLM
llm = OllamaLLM(model="llama3")

# Criar o prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "VocÃª Ã© um analista de dados especializado..."),
    ("user", "question: {question}")
])

# Criar a chain de execuÃ§Ã£o
chain = prompt | llm | StrOutputParser()
```

## ğŸ” Qualidade de CÃ³digo

O projeto utiliza **pre-commit** com os seguintes hooks:

| Hook | DescriÃ§Ã£o |
|------|-----------|
| **Black** | FormataÃ§Ã£o automÃ¡tica de cÃ³digo |
| **Flake8** | Linting e verificaÃ§Ã£o de estilo |
| **isort** | OrdenaÃ§Ã£o de imports |
| **Bandit** | AnÃ¡lise de seguranÃ§a |
| **trailing-whitespace** | Remove espaÃ§os em branco |
| **end-of-file-fixer** | Garante nova linha no final |

```bash
# Instalar hooks
pre-commit install

# Executar em todos os arquivos
pre-commit run --all-files
```

## ğŸ› Troubleshooting

### âŒ Erro de ConexÃ£o com PostgreSQL
```
connection to server at "localhost" (127.0.0.1), port 5433 failed
```
**SoluÃ§Ã£o:** Verifique se o container Docker estÃ¡ rodando:
```bash
docker-compose ps
docker-compose up -d
```

### âŒ MÃ³dulo psycopg2 NÃ£o Encontrado
```
ModuleNotFoundError: No module named 'psycopg2'
```
**SoluÃ§Ã£o:** Instale as dependÃªncias com Poetry:
```bash
poetry install
poetry shell
```

### âŒ Ollama NÃ£o Conecta
```
Connection refused: localhost:11434
```
**SoluÃ§Ã£o:** Verifique se o Ollama estÃ¡ rodando:
```bash
ollama serve
ollama list
```

### âŒ Modelo Llama3 NÃ£o Encontrado
```
model "llama3" not found
```
**SoluÃ§Ã£o:** Baixe o modelo:
```bash
ollama pull llama3
```

## ğŸ“š Recursos e ReferÃªncias

- [ğŸ“– LangChain Documentation](https://python.langchain.com/docs/)
- [ğŸ¦™ Ollama Documentation](https://ollama.ai/)
- [ğŸ˜ PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [ğŸ³ Docker Documentation](https://docs.docker.com/)
- [ğŸ“¦ Poetry Documentation](https://python-poetry.org/docs/)

## ğŸ”„ PrÃ³ximos Passos e Melhorias

- [ ] **ğŸ“Š Dashboard**: VisualizaÃ§Ã£o dos insights com Streamlit
- [ ] **ğŸ§ª Testes**: Testes unitÃ¡rios e de integraÃ§Ã£o com pytest
- [ ] **ğŸ“ˆ MÃ©tricas**: Logging e monitoramento de execuÃ§Ã£o
- [ ] **ğŸ”„ Scheduling**: Agendamento de execuÃ§Ã£o com Airflow ou Prefect
- [ ] **â˜ï¸ Cloud**: Deploy em ambiente cloud (AWS/GCP/Azure)
- [ ] **ğŸ¤– Modelos**: Suporte a outros LLMs (GPT-4, Claude, Gemini)

## ğŸ“ Suporte e Contato

**Jadeson Bruno**
- ğŸ“§ Email: jadesonbruno.a@outlook.com
- ğŸ™ GitHub: [@JadesonBruno](https://github.com/JadesonBruno)
- ğŸ’¼ LinkedIn: [Jadeson Bruno](https://www.linkedin.com/in/jadeson-silva/)

---

â­ **Se este projeto foi Ãºtil, deixe uma estrela no repositÃ³rio!**

ğŸ“ **LicenÃ§a**: MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.
